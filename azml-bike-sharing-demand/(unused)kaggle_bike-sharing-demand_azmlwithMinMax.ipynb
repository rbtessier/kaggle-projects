{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Kaggle Bike Sharing using Azure ML\n",
    "Here I'm trying to apply what I've learned from the Azure DP 100 training LP 2 MODs 1-3 on doing ML and storing data in Azure ML Service. I've taken a model I've trained to predict bicycle rental counts per hour for a Kaggle learning competition on bike demand. I was applying knowledge I learned in a book called principles of Data Science in that I learned how to split nominal columns into dummy variables.\n",
    "\n",
    "Since I'm doing this with my local JupyterLab, this is also a test of using the Azure ML Python SDK on my local machine - and not on the notebooks provided by the ```myCIWorkstateionRyan``` Compute Instance. Apparently I can store notebooks independently in workspace storage and open them in any VM - so I suspect I can get these files from here as well, I will have to look into that!!!\n",
    "\n",
    "Perhaps next I will try to finish what I've started with house price prediction data.\n",
    "\n",
    "**For this experiment, I'll use what was learned in MOD 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the workspace from config file\n",
    "from azureml.core import Workspace #experiment imported to run experiment lol\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.core.workspace.Workspace"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myCIWorkstationRyan : ComputeInstance\n",
      "myCClusterRyan : AmlCompute\n"
     ]
    }
   ],
   "source": [
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(compute.name, \":\", compute.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bike-share-training\\\\test.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'bike-share-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('train.csv', os.path.join(training_folder, \"train.csv\"))\n",
    "shutil.copy('test.csv', os.path.join(training_folder, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bike-share-training/bike-share-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/bike-share-training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def when_is_it(hour):\n",
    "    if hour >=5 and hour < 11:\n",
    "        return 'morning'\n",
    "    elif hour >=11 and hour < 16:\n",
    "        return 'afternoon'\n",
    "    elif hour >=16 and hour < 18:\n",
    "        return 'rush_hour'\n",
    "    else:\n",
    "        return 'off_hours'\n",
    "\n",
    "def season_is_it(season_int):\n",
    "    if season_int == 1:\n",
    "        return 'spring'\n",
    "    elif season_int == 2:\n",
    "        return 'summer'\n",
    "    elif season_int == 3:\n",
    "        return 'fall'\n",
    "    else:\n",
    "        return 'winter'\n",
    "    \n",
    "def weather_is_it(weather_int):\n",
    "    if weather_int == 1:\n",
    "        return 'nice'\n",
    "    elif weather_int == 2:\n",
    "        return 'misty'\n",
    "    elif weather_int == 3:\n",
    "        return 'ugly'\n",
    "    else:\n",
    "        return 'stormy'\n",
    "    \n",
    "#function takes all nominal features and converts to dummy features\n",
    "def dummy_conversion(data): \n",
    "    #create the rules for each dummy variable\n",
    "    df_when_is_it = data['when_is_it'].apply(when_is_it)\n",
    "    df_season_is_it = data['season'].apply(season_is_it)\n",
    "    df_weather_is_it = data['weather'].apply(weather_is_it)\n",
    "    \n",
    "    \n",
    "    when_dummies = pd.get_dummies(df_when_is_it, prefix = 'when_')    \n",
    "    season_dummies = pd.get_dummies(df_season_is_it, prefix = 'season_')\n",
    "    weather_dummies = pd.get_dummies(df_weather_is_it, prefix = 'weather_')\n",
    "    \n",
    "    #drop the old nominal veriables\n",
    "    data=data.drop('datetime', axis = 1 )\n",
    "    data=data.drop('season', axis = 1)\n",
    "    data=data.drop('weather', axis = 1)\n",
    "    \n",
    "    data[list(when_dummies.columns)] = when_dummies\n",
    "    data[list(season_dummies.columns)] = season_dummies\n",
    "    data[list(weather_dummies.columns)] = weather_dummies\n",
    "    return data       \n",
    "\n",
    "#imports train.csv    \n",
    "bikes = pd.read_csv('train.csv')\n",
    "#imports test data and saves a temporary record of the datetime column\n",
    "test_data = pd.read_csv('test.csv')\n",
    "temp_datetime = pd.read_csv('test.csv')['datetime']\n",
    "\n",
    "feature_cols = ['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "       'atemp', 'humidity', 'windspeed']    \n",
    "\n",
    "#saves the labels and the featurs of the training data separately\n",
    "y = bikes['count']\n",
    "bikes=bikes[feature_cols]\n",
    "\n",
    "#splites up the datetime into a nicer format\n",
    "bikes['when_is_it']= bikes['datetime'].apply(lambda x:int(x[11]+x[12]))\n",
    "test_data['when_is_it'] = test_data['datetime'].apply(lambda x:int(x[11]+x[12]))\n",
    "                      \n",
    "\n",
    "\n",
    "#converts datetime, season and weather nominal variables into dummy variable columns\n",
    "X=dummy_conversion(bikes)\n",
    "test_data=dummy_conversion(test_data)\n",
    "\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('train.csv')\n",
    "\n",
    "#initiates preprocessing StandardScaler - which is different from MinMaxScaler I assume, that's what I used last time.\n",
    "#if I decide to use argparser, here's a place I could use it.\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "#fits scaler to X\n",
    "scaler.fit(X)\n",
    "\n",
    "#sets X to normalized values\n",
    "X=scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    #X_train[feature_cols] = scaler.transform(X_train[feature_cols])\n",
    "    #X_test[feature_cols] = scaler.transform(X_test[feature_cols])\n",
    "    #X_train and y_train will be used to train the model\n",
    "    #X_test and y_test will be used to test the model\n",
    "    #remember that all four of these variables are just subsets of the overall X and Y\n",
    "    \n",
    "    \n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "\n",
    "# Train a linear regression model\n",
    "print('Training a linear regression model')\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "\n",
    "#ensure negative values predict 0, since negatives make no sense here\n",
    "y_hat[y_hat <0] = 0\n",
    "    \n",
    "error = np.sqrt(metrics.mean_squared_log_error(y_test, y_hat))\n",
    "    #error = np.sqrt(metrics.mean_squared_log_error(y_test, y_pred))\n",
    "    # calculate our metric\n",
    "\n",
    "#logs the error, its extra cool to see this on my Run Metrics in the ML Service \n",
    "run.log('Root Mean Squared Log Error', np.float(error))\n",
    "\n",
    "\n",
    "# calculate AUC - not relevant since this is regression, just commenting it out to remember this later\n",
    "#y_scores = model.predict_proba(X_test)\n",
    "#auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "#print('AUC: ' + str(auc))\n",
    "#run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/bike_share_model_StandardScale_LinRegression.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From lab: Use an Estimator to Run the Script as an Experiment\n",
    "\n",
    "You can run experiment scripts using a **RunConfiguration** and a **ScriptRunConfig**, or you can use an **Estimator**, which abstracts both of these configurations in a single object.\n",
    "\n",
    "In this case, we'll use a generic **Estimator** object to run the training experiment. Note that the default environment for this estimator does not include the **scikit-learn** package, so you need to explicitly add that to the configuration. The conda environment is built on-demand the first time the estimator is used, and cached for future runs that use the same configuration; so the first run will take a little longer. On subsequent runs, the cached environment can be re-used so they'll complete more quickly.\n",
    "\n",
    "From Ryan: The following script produced errors and highlights the need to have a template for these things:\n",
    "- First Error fixed by changing compute_target to 'myCIWorkstationRyan' as opposed to local, but I think I should try local after this as it can take a long time when running and experiment. \n",
    "- Second error ran a long time before throwing an error because I didn't make a ```test.csv``` file in a folder. \n",
    "\n",
    "Lesson learned here: getting things wrong can lead to a lot of frustration because it takes so long to spoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490\n",
      "Web View: https://ml.azure.com/experiments/bike-share-training-MinMaxScaler-LinearRegression/runs/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490?wsid=/subscriptions/72656d3a-fc47-4387-8c69-13f86d502d86/resourcegroups/myMLResourceGroup/workspaces/myMLWorkspace1\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-07-29T19:52:25Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-07-29T19:52:25Z Starting output-watcher...\n",
      "2020-07-29T19:52:25Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2020-07-29T19:52:25Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_18a2c352852de1e0e7ad8b589dd0927b\n",
      "Digest: sha256:e5fe3e923746f15f646bde32cd52f130f67f9aae3a78019062e698b5e423424f\n",
      "Status: Image is up to date for mymlworkspac527749d0.azurecr.io/azureml/azureml_18a2c352852de1e0e7ad8b589dd0927b:latest\n",
      "mymlworkspac527749d0.azurecr.io/azureml/azureml_18a2c352852de1e0e7ad8b589dd0927b:latest\n",
      "2020-07-29T19:52:27Z 624c25739f4089499574e5b023a842c329e45e6f9eb8f156b0537995d3230c8e\n",
      "2020-07-29T19:52:27Z \n",
      "2020/07/29 19:52:27 Starting App Insight Logger for task:  containerSetup\n",
      "2020/07/29 19:52:27 Version: 3.0.01287.0002 Branch: hotfixxdsnullexception Commit: dfcc21bd\n",
      "2020/07/29 19:52:27 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/07/29 19:52:27 sshd inside container not required for job, skipping setup.\n",
      "2020/07/29 19:52:28 All App Insights Logs was send successfully\n",
      "2020-07-29T19:52:34Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2020/07/29 19:52:23 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2020/07/29 19:52:23 Version: 3.0.01287.0002 Branch: hotfixxdsnullexception Commit: dfcc21bd\n",
      ">>>   2020/07/29 19:52:23 DetonationChamber is not enabled on this subscription: 72656d3a-fc47-4387-8c69-13f86d502d86\n",
      ">>>   2020/07/29 19:52:23 GPU count found: 0\n",
      ">>>   2020/07/29 19:52:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/config\n",
      ">>>   2020/07/29 19:52:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/wd\n",
      ">>>   2020/07/29 19:52:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/shared\n",
      ">>>   2020/07/29 19:52:23 Mounting job level file systems\n",
      ">>>   2020/07/29 19:52:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts\n",
      ">>>   2020/07/29 19:52:23 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/config/.amlcompute.datastorecredentials\n",
      ">>>   2020/07/29 19:52:23 Datastore credentials file not found, skipping.\n",
      ">>>   2020/07/29 19:52:23 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/config/.master.runtimesastokens\n",
      ">>>   2020/07/29 19:52:23 Runtime sas tokens file not found, skipping.\n",
      ">>>   2020/07/29 19:52:23 Start to pulling docker image: mymlworkspac527749d0.azurecr.io/azureml/azureml_18a2c352852de1e0e7ad8b589dd0927b\n",
      ">>>   2020/07/29 19:52:23 No NFS configured\n",
      ">>>   2020/07/29 19:52:23 Requesting XDS for registry details.\n",
      ">>>   2020/07/29 19:52:23 Attempt 1 of http call to https://westus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/72656d3a-fc47-4387-8c69-13f86d502d86/resourceGroups/mymlresourcegroup/workspaces/mymlworkspace1/clusters/myciworkstationryan/nodes/tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d?api-version=2018-02-01\n",
      ">>>   2020/07/29 19:52:23 No Azure File Shares configured\n",
      ">>>   2020/07/29 19:52:23 Mounting blob file systems\n",
      ">>>   2020/07/29 19:52:23 Mounting azureml-blobstore-f4d52ca6-9706-477b-af81-209f2b12edc3 container from mymlworkspace13138199723 account at /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore\n",
      ">>>   2020/07/29 19:52:23 Error opening env file:  open /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2020/07/29 19:52:23 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/07/29 19:52:23 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/07/29 19:52:23 Running following command: &{/bin/bash [bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/configs/workspaceblobstore.cfg --log-level=LOG_WARNING] []  <nil>   [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/07/29 19:52:23 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore\n",
      ">>>   2020/07/29 19:52:23 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore\n",
      ">>>   2020/07/29 19:52:23 Successfully mounted azureml-blobstore-f4d52ca6-9706-477b-af81-209f2b12edc3 container from mymlworkspace13138199723 account at /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore\n",
      ">>>   2020/07/29 19:52:23 No unmanaged file systems configured\n",
      ">>>   2020/07/29 19:52:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml_compute_logs\n",
      ">>>   2020/07/29 19:52:23 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2020/07/29 19:52:23 Got container registry details from credentials service.\n",
      ">>>   2020/07/29 19:52:23 Writing ACR Details to file...\n",
      ">>>   2020/07/29 19:52:23 Copying ACR Details file to worker nodes...\n",
      ">>>   2020/07/29 19:52:23 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2020/07/29 19:52:25 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/logs\n",
      ">>>   2020/07/29 19:52:25 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/outputs\n",
      ">>>   2020/07/29 19:52:25 Starting output-watcher...\n",
      ">>>   2020/07/29 19:52:25 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2020/07/29 19:52:26 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2020/07/29 19:52:26 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490 -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/workitems/9b09e76c-dd32-41de-ab1f-90788c8cae85/job-1/bike-share-training-_31df33c3-f3e0-4da0-9220-20355f4ebff2/certs:/mnt/batch/tasks/workitems/9b09e76c-dd32-41de-ab1f-90788c8cae85/job-1/bike-share-training-_31df33c3-f3e0-4da0-9220-20355f4ebff2/certs -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml_compute_logs -v /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490:/mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490 -v /mnt/batch/tasks/workitems/9b09e76c-dd32-41de-ab1f-90788c8cae85/job-1/bike-share-training-_31df33c3-f3e0-4da0-9220-20355f4ebff2/wd:/mnt/batch/tasks/workitems/9b09e76c-dd32-41de-ab1f-90788c8cae85/job-1/bike-share-training-_31df33c3-f3e0-4da0-9220-20355f4ebff2/wd -v /opt/azureml:/opt/azureml:ro -w /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/config/.batchai.envlist --shm-size 2g -d -it --privileged --net=host mymlworkspac527749d0.azurecr.io/azureml/azureml_18a2c352852de1e0e7ad8b589dd0927b\n",
      ">>>   2020/07/29 19:52:27 624c25739f4089499574e5b023a842c329e45e6f9eb8f156b0537995d3230c8e\n",
      ">>>   2020/07/29 19:52:27 \n",
      ">>>   2020/07/29 19:52:28 Container ssh is not required for job type.\n",
      ">>>   2020/07/29 19:52:28 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml_compute_logs\n",
      ">>>   2020/07/29 19:52:28 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/bin/python $AZ_BATCHAI_INPUT_AZUREML/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490-setup/job_prep.py --snapshots '[{\"Id\":\"88b949fb-3ac6-4f56-8244-c001da9edbf8\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/07/29 19:52:28 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml_compute_logs/65_job_prep-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt\n",
      ">>>   2020/07/29 19:52:28 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml_compute_logs/65_job_prep-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt\n",
      ">>>   2020/07/29 19:52:28 runSpecialJobTask: Running cmd: &{/usr/bin/docker [docker exec -t bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490 bash -c source /etc/bash.bashrc; PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/mymlworkspace1/azureml/bike-share-training-minmaxscaler-linearregression_1596052335_4e6c3490/mounts/workspaceblobstore/azureml/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490;/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/bin/python $AZ_BATCHAI_INPUT_AZUREML/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490-setup/job_prep.py --snapshots '[{\"Id\":\"88b949fb-3ac6-4f56-8244-c001da9edbf8\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'] []  <nil> <nil> <nil> [] <nil> <nil> <nil> <nil> <nil> false [] [] [] [] <nil> <nil>}\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:29.208314] Entering job preparation.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.580327] TimeoutHandler __init__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.580385] TimeoutHandler __enter__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.581596] Starting job preparation.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.581621] Extracting the control code.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.600227] fetching and extracting the control code on master node.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.600266] Starting extract_project.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:30.600311] Starting to extract zip file.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.260280] Finished extracting zip file.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.391453] Using urllib.request Python 3.0 or later\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.391523] Start fetching snapshots.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.391565] Start fetching snapshot.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.391580] Retrieving project from snapshot: 88b949fb-3ac6-4f56-8244-c001da9edbf8\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 40\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.392492] Start RetrieveProjectSasUrls\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.734479] Finished RetrieveProjectSasUrls\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.734537] TimeoutHandler __init__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.734550] TimeoutHandler __enter__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.735832] TimeoutHandler __exit__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.735858] Starting project file download.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.750735] Starting _download_tree for file.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.750854] _download_tree start request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.860298] _download_tree finished request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.860373] _download_tree start writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.860385] TimeoutHandler __init__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.860409] TimeoutHandler __enter__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.893719] TimeoutHandler __exit__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.893762] _download_tree finished writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.893799] Starting _download_tree for file.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.894197] _download_tree start request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.916569] _download_tree finished request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.916602] _download_tree start writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.916616] TimeoutHandler __init__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.916630] TimeoutHandler __enter__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.927227] TimeoutHandler __exit__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.927399] _download_tree finished writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.927461] Starting _download_tree for file.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.927837] _download_tree start request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.951019] _download_tree finished request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.951052] _download_tree start writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.951065] TimeoutHandler __init__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.951081] TimeoutHandler __enter__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.972948] TimeoutHandler __exit__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.972995] _download_tree finished writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.973065] Starting _download_tree for file.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.973221] _download_tree start request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.997564] _download_tree finished request for file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.997604] _download_tree start writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.997634] TimeoutHandler __init__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:31.997662] TimeoutHandler __enter__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.031223] TimeoutHandler __exit__\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.031278] _download_tree finished writing file\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.031339] Finished project file download.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.031390] Finished fetching snapshot.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.031443] Finished fetching snapshots.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.031457] Finished extract_project.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.041739] Finished fetching and extracting the control code.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.044497] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.045553] Start run_history_prep.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.099190] Entering context manager injector.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.781424] downloadDataStore completed\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.784246] Job preparation is complete.\n",
      ">>>   2020/07/29 19:52:32 runSpecialJobTask: preparation: [2020-07-29T19:52:32.784405] TimeoutHandler __exit__\n",
      ">>>   2020/07/29 19:52:34 All App Insights Logs was send successfully\n",
      ">>>   2020/07/29 19:52:34 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2020-07-29T19:52:34Z 127.0.0.1 slots=2 max-slots=2\n",
      "2020-07-29T19:52:34Z launching Custom job\n",
      "2020-07-29T19:52:40Z job exited with code 0\n",
      "2020-07-29T19:52:40Z Executing 'JobRelease task' on 10.0.0.5\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-07-29T19:52:41.143803\n",
      "Starting job release. Current time:2020-07-29T19:52:42.056258\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 113\n",
      "[2020-07-29T19:52:42.071644] Entering context manager injector.\n",
      "Job release is complete. Current time:2020-07-29T19:52:43.262271\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490\n",
      "Web View: https://ml.azure.com/experiments/bike-share-training-MinMaxScaler-LinearRegression/runs/bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490?wsid=/subscriptions/72656d3a-fc47-4387-8c69-13f86d502d86/resourcegroups/myMLResourceGroup/workspaces/myMLWorkspace1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490',\n",
       " 'target': 'myCIWorkstationRyan',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-07-29T19:52:29.230189Z',\n",
       " 'endTimeUtc': '2020-07-29T19:52:50.433216Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '30bdec04-e9c1-4b13-9801-3d887c2aedb3',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'bike-share-training.py',\n",
       "  'scriptType': None,\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'myCIWorkstationRyan',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment bike-share-training-MinMaxScaler-LinearRegression Environment',\n",
       "   'version': 'Autosave_2020-07-29T19:42:30Z_ca30f74a',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn'],\n",
       "     'name': 'azureml_4b824bcb98517d791c41923f24d65461'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml-logs/55_azureml-execution-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt?sv=2019-02-02&sr=b&sig=VMhSTh%2B%2FWts7Yd7tYfz%2BV4HSymJb40K6ffbyI0yyP2E%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml-logs/65_job_prep-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt?sv=2019-02-02&sr=b&sig=ij0ruOraP5QyZC2qRfnpjqG73W4wmeftLhc9dt%2BDezs%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=w30Yao5RBxdhtCSPwTW6IEf6Y5uRsYmPVDJz6%2BPQXsA%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml-logs/75_job_post-tvmps_9f154f53a68892668b6ff741dfaeba7c8c6ff30ec94f3ec0fb58959269f5ec51_d.txt?sv=2019-02-02&sr=b&sig=IIIKPhKiNM%2F5RGdTRNAUZA52q273ch%2B1rZFOnNKHEIY%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=%2B6oRBSfFRhs4DCKpKx4PbHTKNPJU8Bh%2FhOl%2FWd4jUAw%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=kEDrggKQ4kVbMs7lLxJUpXp4zaQD%2F6gdhCC2kvMVirg%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'logs/azureml/93_azureml.log': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/logs/azureml/93_azureml.log?sv=2019-02-02&sr=b&sig=T9OUjRw%2B%2FPqm28yBe5qhSETZ0uDzp6mezrsEXwdsX%2FY%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=TOffFjp6QLVdoZRxYg%2FMcU8cQ17UrUfdhnroOoMGQKU%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mymlworkspace13138199723.blob.core.windows.net/azureml/ExperimentRun/dcid.bike-share-training-MinMaxScaler-LinearRegression_1596052335_4e6c3490/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=eSnH0ZjP2RoQ5vTUUpICpmf16fm8KYhW4fSW2DvTf%2FY%3D&st=2020-07-29T19%3A42%3A55Z&se=2020-07-30T03%3A52%3A55Z&sp=r'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                      entry_script='bike-share-training.py',\n",
    "                      compute_target='myCIWorkstationRyan',\n",
    "                      conda_packages=['scikit-learn']\n",
    "                      )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'bike-share-training-MinMaxScaler-LinearRegression'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "run = experiment.submit(config=estimator)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using MinMax Scaler again, going to see what sort of metrics I get,, with new model ```bike-share-training-MinMaxScaler-LinearRegression```\n",
    "- Run 1 1.1645\n",
    "- Run 2 1.1800\n",
    "- Run 3 1.2214\n",
    "- Run 4 1.2879\n",
    "- Run 5 1.2072\n",
    "Average is 1.21, so maybe the Standard Scaler better on average model\n",
    "So I won't do the model registration here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AutoMLd9d5ac31d0': Model(workspace=Workspace.create(name='myMLWorkspace1', subscription_id='72656d3a-fc47-4387-8c69-13f86d502d86', resource_group='myMLResourceGroup'), name=AutoMLd9d5ac31d0, id=AutoMLd9d5ac31d0:1, version=1, tags={}, properties={}),\n",
       " 'AutoML50b56166512': Model(workspace=Workspace.create(name='myMLWorkspace1', subscription_id='72656d3a-fc47-4387-8c69-13f86d502d86', resource_group='myMLResourceGroup'), name=AutoML50b56166512, id=AutoML50b56166512:1, version=1, tags={}, properties={}),\n",
       " 'amlstudio-predict-auto-price': Model(workspace=Workspace.create(name='myMLWorkspace1', subscription_id='72656d3a-fc47-4387-8c69-13f86d502d86', resource_group='myMLResourceGroup'), name=amlstudio-predict-auto-price, id=amlstudio-predict-auto-price:1, version=1, tags={'CreatedByAMLStudio': 'true'}, properties={}),\n",
       " 'amlstudio-predict-diabetes': Model(workspace=Workspace.create(name='myMLWorkspace1', subscription_id='72656d3a-fc47-4387-8c69-13f86d502d86', resource_group='myMLResourceGroup'), name=amlstudio-predict-diabetes, id=amlstudio-predict-diabetes:1, version=1, tags={'CreatedByAMLStudio': 'true'}, properties={}),\n",
       " 'amlstudio-predict-iris-cluster': Model(workspace=Workspace.create(name='myMLWorkspace1', subscription_id='72656d3a-fc47-4387-8c69-13f86d502d86', resource_group='myMLResourceGroup'), name=amlstudio-predict-iris-cluster, id=amlstudio-predict-iris-cluster:1, version=1, tags={'CreatedByAMLStudio': 'true'}, properties={}),\n",
       " 'diabetes_model': Model(workspace=Workspace.create(name='myMLWorkspace1', subscription_id='72656d3a-fc47-4387-8c69-13f86d502d86', resource_group='myMLResourceGroup'), name=diabetes_model, id=diabetes_model:3, version=3, tags={'Training context': 'Parameterized SKLearn Estimator'}, properties={'AUC': '0.8483904671874223', 'Accuracy': '0.7736666666666666'})}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(test_data)\n",
    "test_data=scaler.transform(test_data)\n",
    "\n",
    "predictions = linreg.predict(test_data)\n",
    "#ensure all negative values predict 0\n",
    "predictions[predictions <0] = 0 \n",
    "\n",
    "#ensure all counts are rounded\n",
    "predictions = np.rint(predictions)\n",
    "submission = pd.DataFrame({'datetime': temp_datetime, 'count': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  count\n",
       "0  2011-01-20 00:00:00    0.0\n",
       "1  2011-01-20 01:00:00    0.0\n",
       "2  2011-01-20 02:00:00    0.0\n",
       "3  2011-01-20 03:00:00    0.0\n",
       "4  2011-01-20 04:00:00    6.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('linReg_submission2.csv', index=False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/bike-sharing-demand\n",
    "Above is the link I submit to. I officially got 1.46 RMSLE on the site when I submitted without dummy variables, but included scaling. \n",
    "\n",
    "My new submission... GOT 1.199984 = 1.2 RMSLE WOOOOOOOOO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
